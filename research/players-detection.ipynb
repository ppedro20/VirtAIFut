{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 14 18:21:51 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 571.96                 Driver Version: 571.96         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   50C    P5              8W /   50W |     838MiB /   4096MiB |      9%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            1568    C+G   ...indows\\System32\\ShellHost.exe      N/A      |\n",
      "|    0   N/A  N/A            4412    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A            4636    C+G   ...xyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A            6168    C+G   ...em32\\ApplicationFrameHost.exe      N/A      |\n",
      "|    0   N/A  N/A            7312    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A            7748    C+G   ...Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A            9324    C+G   ....0.3179.73\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A            9916    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           10080    C+G   ...ntrolPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A           12876    C+G   ...x64__dt26b99r8h8gj\\RtkUWP.exe      N/A      |\n",
      "|    0   N/A  N/A           13348    C+G   ..._cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A           14552    C+G   ...ms\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A           18720    C+G   ...64__zpdnekdrzrea0\\Spotify.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q gdown inference-gpu\n",
    "!pip install -q onnxruntime-gpu==1.18.0 --index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/roboflow/sports.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: supervision 0.25.1\n",
      "Uninstalling supervision-0.25.1:\n",
      "  Successfully uninstalled supervision-0.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y supervision && pip install -q supervision>=0.23.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"ONNXRUNTIME_EXECUTION_PROVIDERS\"] = \"[CUDAExecutionProvider]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/14/25 18:22:15] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Your inference package version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.43</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> is out of date! Please upgrade to <a href=\"file://C:\\Users\\pedro\\AppData\\Roaming\\Python\\Python312\\site-packages\\inference\\core\\__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\pedro\\AppData\\Roaming\\Python\\Python312\\site-packages\\inference\\core\\__init__.py#41\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">41</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.46</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of inference for the latest features and bug fixes by    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         running `pip install --upgrade inference`.                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/14/25 18:22:15]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Your inference package version \u001b[1;36m0.43\u001b[0m.\u001b[1;36m0\u001b[0m is out of date! Please upgrade to \u001b]8;id=266804;file://C:\\Users\\pedro\\AppData\\Roaming\\Python\\Python312\\site-packages\\inference\\core\\__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=983355;file://C:\\Users\\pedro\\AppData\\Roaming\\Python\\Python312\\site-packages\\inference\\core\\__init__.py#41\u001b\\\u001b[2m41\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         version \u001b[1;36m0.46\u001b[0m.\u001b[1;36m4\u001b[0m of inference for the latest features and bug fixes by    \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         running `pip install --upgrade inference`.                              \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from inference import get_model\n",
    "\n",
    "ROBOFLOW_API_KEY = 'tCy476DHnSoq6mwGtVpp'\n",
    "PLAYER_DETECTION_MODEL_ID = 'football-players-detection-3zvbc/12'\n",
    "PLAYER_DETECTION_MODEL = get_model(PLAYER_DETECTION_MODEL_ID, ROBOFLOW_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "\n",
    "SOURCE_VIDEO_PATH = \"content/08fd33_4.mp4\"\n",
    "\n",
    "box_annotator = sv.BoxAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(['#FF8C00', '#00BFFF', '#FF1493', '#FFD700']),\n",
    "    thickness=2\n",
    ")\n",
    "label_annotator = sv.LabelAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(['#FF8C00', '#00BFFF', '#FF1493', '#FFD700']),\n",
    "    text_color=sv.Color.from_hex('#000000')\n",
    ")\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "frame = next(frame_generator)\n",
    "\n",
    "result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "detections = sv.Detections.from_inference(result)\n",
    "\n",
    "labels = [\n",
    "    f\"{class_name} {confidence:.2f}\"\n",
    "    for class_name, confidence\n",
    "    in zip(detections['class_name'], detections.confidence)\n",
    "]\n",
    "\n",
    "annotated_frame = frame.copy()\n",
    "annotated_frame = box_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    detections=detections)\n",
    "annotated_frame = label_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    detections=detections,\n",
    "    labels=labels)\n",
    "\n",
    "sv.plot_image(annotated_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "\n",
    "SOURCE_VIDEO_PATH = \"content/08fd33_4.mp4\"\n",
    "BALL_ID = 0\n",
    "\n",
    "ellipse_annotator = sv.EllipseAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
    "    thickness=2\n",
    ")\n",
    "triangle_annotator = sv.TriangleAnnotator(\n",
    "    color=sv.Color.from_hex('#FFD700'),\n",
    "    base=25,\n",
    "    height=21,\n",
    "    outline_thickness=1\n",
    ")\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "frame = next(frame_generator)\n",
    "\n",
    "result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "detections = sv.Detections.from_inference(result)\n",
    "\n",
    "ball_detections = detections[detections.class_id == BALL_ID]\n",
    "ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
    "\n",
    "all_detections = detections[detections.class_id != BALL_ID]\n",
    "all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)\n",
    "all_detections.class_id -= 1\n",
    "\n",
    "annotated_frame = frame.copy()\n",
    "annotated_frame = ellipse_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    detections=all_detections)\n",
    "annotated_frame = triangle_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    detections=ball_detections)\n",
    "\n",
    "sv.plot_image(annotated_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "\n",
    "SOURCE_VIDEO_PATH = \"content/08fd33_4.mp4\"\n",
    "BALL_ID = 0\n",
    "\n",
    "ellipse_annotator = sv.EllipseAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
    "    thickness=2\n",
    ")\n",
    "label_annotator = sv.LabelAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
    "    text_color=sv.Color.from_hex('#000000'),\n",
    "    text_position=sv.Position.BOTTOM_CENTER\n",
    ")\n",
    "triangle_annotator = sv.TriangleAnnotator(\n",
    "    color=sv.Color.from_hex('#FFD700'),\n",
    "    base=25,\n",
    "    height=21,\n",
    "    outline_thickness=1\n",
    ")\n",
    "\n",
    "tracker = sv.ByteTrack()\n",
    "tracker.reset()\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "frame = next(frame_generator)\n",
    "\n",
    "result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "detections = sv.Detections.from_inference(result)\n",
    "\n",
    "ball_detections = detections[detections.class_id == BALL_ID]\n",
    "ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
    "\n",
    "all_detections = detections[detections.class_id != BALL_ID]\n",
    "all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)\n",
    "all_detections.class_id -= 1\n",
    "all_detections = tracker.update_with_detections(detections=all_detections)\n",
    "\n",
    "labels = [\n",
    "    f\"#{tracker_id}\"\n",
    "    for tracker_id\n",
    "    in all_detections.tracker_id\n",
    "]\n",
    "\n",
    "annotated_frame = frame.copy()\n",
    "annotated_frame = ellipse_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    detections=all_detections)\n",
    "annotated_frame = label_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    detections=all_detections,\n",
    "    labels=labels)\n",
    "annotated_frame = triangle_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    detections=ball_detections)\n",
    "\n",
    "sv.plot_image(annotated_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split players into teams with siglip, umap and kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop up players by their bounding boxes\n",
    "from tqdm import tqdm\n",
    "\n",
    "SOURCE_VIDEO_PATH = \"content/08fd33_4.mp4\"\n",
    "PLAYER_ID = 2\n",
    "STRIDE = 30\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(\n",
    "    source_path=SOURCE_VIDEO_PATH, stride=STRIDE)\n",
    "\n",
    "crops = []\n",
    "for frame in tqdm(frame_generator, desc='collecting crops'):\n",
    "    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "    detections = sv.Detections.from_inference(result)\n",
    "    detections = detections.with_nms(threshold=0.5, class_agnostic=True)\n",
    "    detections = detections[detections.class_id == PLAYER_ID]\n",
    "    players_crops = [sv.crop_image(frame, xyxy) for xyxy in detections.xyxy]\n",
    "    crops += players_crops\n",
    " \n",
    "#Note: Here's a sample (100 elements) of the crops we've gathered.   \n",
    "sv.plot_images_grid(crops[:100], grid_size=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: Next, we'll run SigLIP to calculate embeddings for each of the crops.\n",
    "import torch\n",
    "from transformers import AutoProcessor, SiglipVisionModel\n",
    "\n",
    "SIGLIP_MODEL_PATH = 'google/siglip-base-patch16-224'\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "EMBEDDINGS_MODEL = SiglipVisionModel.from_pretrained(SIGLIP_MODEL_PATH).to(DEVICE)\n",
    "EMBEDDINGS_PROCESSOR = AutoProcessor.from_pretrained(SIGLIP_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code performs batch processing of image crops to extract embeddings (numerical representations) using a deep learning model\n",
    "import numpy as np\n",
    "from more_itertools import chunked\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "crops = [sv.cv2_to_pillow(crop) for crop in crops]\n",
    "batches = chunked(crops, BATCH_SIZE)\n",
    "data = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(batches, desc='embedding extraction'):\n",
    "        inputs = EMBEDDINGS_PROCESSOR(images=batch, return_tensors=\"pt\").to(DEVICE)\n",
    "        outputs = EMBEDDINGS_MODEL(**inputs)\n",
    "        embeddings = torch.mean(outputs.last_hidden_state, dim=1).cpu().numpy()\n",
    "        data.append(embeddings)\n",
    "\n",
    "data = np.concatenate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: Using UMAP, we project our embeddings from (N, 768) to (N, 3) and then perform a two-cluster division using KMeans.\n",
    "import umap\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "REDUCER = umap.UMAP(n_components=3)\n",
    "CLUSTERING_MODEL = KMeans(n_clusters=2)\n",
    "\n",
    "projections = REDUCER.fit_transform(data)\n",
    "clusters = CLUSTERING_MODEL.fit_predict(projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "from tqdm import tqdm\n",
    "from sports.common.team import TeamClassifier\n",
    "\n",
    "SOURCE_VIDEO_PATH = \"content/08fd33_4.mp4\"\n",
    "PLAYER_ID = 2\n",
    "STRIDE = 30\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(\n",
    "    source_path=SOURCE_VIDEO_PATH, stride=STRIDE)\n",
    "\n",
    "crops = []\n",
    "for frame in tqdm(frame_generator, desc='collecting crops'):\n",
    "    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "    detections = sv.Detections.from_inference(result)\n",
    "    players_detections = detections[detections.class_id == PLAYER_ID]\n",
    "    players_crops = [sv.crop_image(frame, xyxy) for xyxy in detections.xyxy]\n",
    "    crops += players_crops\n",
    "\n",
    "team_classifier = TeamClassifier(device=\"cpu\")\n",
    "team_classifier.fit(crops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time to assign goalkeepers to teams. We'll use a simple heuristic: \n",
    "# calculate the average position (centroid) of the players belonging to both teams and then assign the goalkeeper to the team whose average position is closer.\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "\n",
    "def resolve_goalkeepers_team_id(\n",
    "    players: sv.Detections,\n",
    "    goalkeepers: sv.Detections\n",
    ") -> np.ndarray:\n",
    "    goalkeepers_xy = goalkeepers.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "    players_xy = players.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "    team_0_centroid = players_xy[players.class_id == 0].mean(axis=0)\n",
    "    team_1_centroid = players_xy[players.class_id == 1].mean(axis=0)\n",
    "    goalkeepers_team_id = []\n",
    "    for goalkeeper_xy in goalkeepers_xy:\n",
    "        dist_0 = np.linalg.norm(goalkeeper_xy - team_0_centroid)\n",
    "        dist_1 = np.linalg.norm(goalkeeper_xy - team_1_centroid)\n",
    "        goalkeepers_team_id.append(0 if dist_0 < dist_1 else 1)\n",
    "\n",
    "    return np.array(goalkeepers_team_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#team assignment and goalkeepers team assignment workking together\n",
    "import supervision as sv\n",
    "\n",
    "SOURCE_VIDEO_PATH = \"content/08fd33_4.mp4\"\n",
    "BALL_ID = 0\n",
    "GOALKEEPER_ID = 1\n",
    "PLAYER_ID = 2\n",
    "REFEREE_ID = 3\n",
    "\n",
    "ellipse_annotator = sv.EllipseAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
    "    thickness=2\n",
    ")\n",
    "label_annotator = sv.LabelAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
    "    text_color=sv.Color.from_hex('#000000'),\n",
    "    text_position=sv.Position.BOTTOM_CENTER\n",
    ")\n",
    "triangle_annotator = sv.TriangleAnnotator(\n",
    "    color=sv.Color.from_hex('#FFD700'),\n",
    "    base=25,\n",
    "    height=21,\n",
    "    outline_thickness=1\n",
    ")\n",
    "\n",
    "tracker = sv.ByteTrack()\n",
    "tracker.reset()\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "frame = next(frame_generator)\n",
    "\n",
    "result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "detections = sv.Detections.from_inference(result)\n",
    "\n",
    "ball_detections = detections[detections.class_id == BALL_ID]\n",
    "ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
    "\n",
    "all_detections = detections[detections.class_id != BALL_ID]\n",
    "all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)\n",
    "all_detections = tracker.update_with_detections(detections=all_detections)\n",
    "\n",
    "goalkeepers_detections = all_detections[all_detections.class_id == GOALKEEPER_ID]\n",
    "players_detections = all_detections[all_detections.class_id == PLAYER_ID]\n",
    "referees_detections = all_detections[all_detections.class_id == REFEREE_ID]\n",
    "\n",
    "players_crops = [sv.crop_image(frame, xyxy) for xyxy in players_detections.xyxy]\n",
    "players_detections.class_id = team_classifier.predict(players_crops)\n",
    "\n",
    "goalkeepers_detections.class_id = resolve_goalkeepers_team_id(\n",
    "    players_detections, goalkeepers_detections)\n",
    "\n",
    "referees_detections.class_id -= 1\n",
    "\n",
    "all_detections = sv.Detections.merge([\n",
    "    players_detections, goalkeepers_detections, referees_detections])\n",
    "\n",
    "labels = [\n",
    "    f\"#{tracker_id}\"\n",
    "    for tracker_id\n",
    "    in all_detections.tracker_id\n",
    "]\n",
    "\n",
    "all_detections.class_id = all_detections.class_id.astype(int)\n",
    "\n",
    "annotated_frame = frame.copy()\n",
    "annotated_frame = ellipse_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    detections=all_detections)\n",
    "annotated_frame = label_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    detections=all_detections,\n",
    "    labels=labels)\n",
    "annotated_frame = triangle_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    detections=ball_detections)\n",
    "\n",
    "sv.plot_image(annotated_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KEYPOINTS SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import get_model\n",
    "\n",
    "ROBOFLOW_API_KEY = 'tCy476DHnSoq6mwGtVpp'\n",
    "FIELD_DETECTION_MODEL_ID = \"football-field-detection-f07vi/15\"\n",
    "FIELD_DETECTION_MODEL = get_model(model_id=FIELD_DETECTION_MODEL_ID, api_key=ROBOFLOW_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "\n",
    "SOURCE_VIDEO_PATH = \"content/08fd33_4.mp4\"\n",
    "\n",
    "vertex_annotator = sv.VertexAnnotator(\n",
    "    color=sv.Color.from_hex('#FF1493'),\n",
    "    radius=8)\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "frame = next(frame_generator)\n",
    "\n",
    "result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "key_points = sv.KeyPoints.from_inference(result)\n",
    "\n",
    "annotated_frame = frame.copy()\n",
    "annotated_frame = vertex_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    key_points=key_points)\n",
    "\n",
    "sv.plot_image(annotated_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter low confidence keypoints\n",
    "import supervision as sv\n",
    "import numpy as np\n",
    "\n",
    "SOURCE_VIDEO_PATH = \"content/08fd33_4.mp4\"\n",
    "\n",
    "vertex_annotator = sv.VertexAnnotator(\n",
    "    color=sv.Color.from_hex('#FF1493'),\n",
    "    radius=8)\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "frame = next(frame_generator)\n",
    "\n",
    "result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "key_points = sv.KeyPoints.from_inference(result)\n",
    "\n",
    "filter = key_points.confidence[0] > 0.5\n",
    "frame_reference_points = key_points.xy[0][filter]\n",
    "frame_reference_key_points = sv.KeyPoints(\n",
    "    xy=frame_reference_points[np.newaxis, ...])\n",
    "\n",
    "annotated_frame = frame.copy()\n",
    "annotated_frame = vertex_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    key_points=frame_reference_key_points)\n",
    "\n",
    "sv.plot_image(annotated_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "project pitch lines on frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sports.annotators.soccer import draw_pitch\n",
    "from sports.configs.soccer import SoccerPitchConfiguration\n",
    "\n",
    "CONFIG = SoccerPitchConfiguration()\n",
    "\n",
    "annotated_frame = draw_pitch(CONFIG)\n",
    "\n",
    "sv.plot_image(annotated_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import supervision as sv\n",
    "from sports.common.view import ViewTransformer\n",
    "\n",
    "SOURCE_VIDEO_PATH = \"content/08fd33_4.mp4\"\n",
    "\n",
    "edge_annotator = sv.EdgeAnnotator(\n",
    "    color=sv.Color.from_hex('#00BFFF'),\n",
    "    thickness=2, edges=CONFIG.edges)\n",
    "vertex_annotator = sv.VertexAnnotator(\n",
    "    color=sv.Color.from_hex('#FF1493'),\n",
    "    radius=8)\n",
    "vertex_annotator_2 = sv.VertexAnnotator(\n",
    "    color=sv.Color.from_hex('#00BFFF'),\n",
    "    radius=8)\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH, start=200)\n",
    "frame = next(frame_generator)\n",
    "\n",
    "result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "key_points = sv.KeyPoints.from_inference(result)\n",
    "\n",
    "filter = key_points.confidence[0] > 0.5\n",
    "frame_reference_points = key_points.xy[0][filter]\n",
    "frame_reference_key_points = sv.KeyPoints(\n",
    "    xy=frame_reference_points[np.newaxis, ...])\n",
    "\n",
    "pitch_reference_points = np.array(CONFIG.vertices)[filter]\n",
    "\n",
    "transformer = ViewTransformer(\n",
    "    source=pitch_reference_points,\n",
    "    target=frame_reference_points\n",
    ")\n",
    "\n",
    "pitch_all_points = np.array(CONFIG.vertices)\n",
    "frame_all_points = transformer.transform_points(points=pitch_all_points)\n",
    "\n",
    "frame_all_key_points = sv.KeyPoints(xy=frame_all_points[np.newaxis, ...])\n",
    "\n",
    "annotated_frame = frame.copy()\n",
    "annotated_frame = edge_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    key_points=frame_all_key_points)\n",
    "annotated_frame = vertex_annotator_2.annotate(\n",
    "    scene=annotated_frame,\n",
    "    key_points=frame_all_key_points)\n",
    "annotated_frame = vertex_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    key_points=frame_reference_key_points)\n",
    "\n",
    "sv.plot_image(annotated_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "project ball, players and referies on pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "from tqdm import tqdm\n",
    "from sports.common.team import TeamClassifier\n",
    "\n",
    "SOURCE_VIDEO_PATH = \"content/08fd33_4.mp4\"\n",
    "PLAYER_ID = 2\n",
    "STRIDE = 30\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(\n",
    "    source_path=SOURCE_VIDEO_PATH, stride=STRIDE)\n",
    "\n",
    "crops = []\n",
    "for frame in tqdm(frame_generator, desc='collecting crops'):\n",
    "    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "    detections = sv.Detections.from_inference(result)\n",
    "    players_detections = detections[detections.class_id == PLAYER_ID]\n",
    "    players_crops = [sv.crop_image(frame, xyxy) for xyxy in detections.xyxy]\n",
    "    crops += players_crops\n",
    "\n",
    "team_classifier = TeamClassifier(device=\"cpu\")\n",
    "team_classifier.fit(crops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "import cv2\n",
    "from sports.annotators.soccer import (\n",
    "    draw_pitch,\n",
    "    draw_points_on_pitch,\n",
    "    draw_pitch_voronoi_diagram\n",
    ")\n",
    "\n",
    "SOURCE_VIDEO_PATH = \"content/08fd33_4.mp4\"\n",
    "TARGET_VIDEO_PATH = \"content/08fd33_4_out.mp4\"\n",
    "BALL_ID = 0\n",
    "GOALKEEPER_ID = 1\n",
    "PLAYER_ID = 2\n",
    "REFEREE_ID = 3\n",
    "\n",
    "ellipse_annotator = sv.EllipseAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
    "    thickness=2\n",
    ")\n",
    "label_annotator = sv.LabelAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
    "    text_color=sv.Color.from_hex('#000000'),\n",
    "    text_position=sv.Position.BOTTOM_CENTER\n",
    ")\n",
    "triangle_annotator = sv.TriangleAnnotator(\n",
    "    color=sv.Color.from_hex('#FFD700'),\n",
    "    base=20, height=17\n",
    ")\n",
    "\n",
    "tracker = sv.ByteTrack()\n",
    "tracker.reset()\n",
    "\n",
    "# Initialize a list to store every 10th frame\n",
    "frames = []\n",
    "stride = 40 #change to be faster\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH,stride)\n",
    "\n",
    "#frame counter\n",
    "frame_counter = 0\n",
    "\n",
    "# Iterate through the frame generator and save each frame\n",
    "for frame in frame_generator:\n",
    "    frame_counter += 1\n",
    "    \n",
    "    # ball, goalkeeper, player, referee detection\n",
    "\n",
    "    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.2)[0]\n",
    "    detections = sv.Detections.from_inference(result)\n",
    "\n",
    "    ball_detections = detections[detections.class_id == BALL_ID]\n",
    "    ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
    "\n",
    "    all_detections = detections[detections.class_id != BALL_ID]\n",
    "    all_detections = all_detections.with_nms(threshold=0.3, class_agnostic=True)\n",
    "    all_detections = tracker.update_with_detections(detections=all_detections)\n",
    "\n",
    "    goalkeepers_detections = all_detections[all_detections.class_id == GOALKEEPER_ID]\n",
    "    players_detections = all_detections[all_detections.class_id == PLAYER_ID]\n",
    "    referees_detections = all_detections[all_detections.class_id == REFEREE_ID]\n",
    "\n",
    "    # team assignment\n",
    "\n",
    "    players_crops = [sv.crop_image(frame, xyxy) for xyxy in players_detections.xyxy]\n",
    "    players_detections.class_id = team_classifier.predict(players_crops)\n",
    "\n",
    "    goalkeepers_detections.class_id = resolve_goalkeepers_team_id(\n",
    "        players_detections, goalkeepers_detections)\n",
    "\n",
    "    referees_detections.class_id -= 1\n",
    "\n",
    "    all_detections = sv.Detections.merge([\n",
    "        players_detections, goalkeepers_detections, referees_detections])\n",
    "\n",
    "    # frame visualization\n",
    "\n",
    "    labels = [\n",
    "        f\"#{tracker_id}\"\n",
    "        for tracker_id\n",
    "        in all_detections.tracker_id\n",
    "    ]\n",
    "\n",
    "    all_detections.class_id = all_detections.class_id.astype(int)\n",
    "\n",
    "    annotated_frame = frame.copy()\n",
    "    annotated_frame = ellipse_annotator.annotate(\n",
    "        scene=annotated_frame,\n",
    "        detections=all_detections)\n",
    "    annotated_frame = label_annotator.annotate(\n",
    "        scene=annotated_frame,\n",
    "        detections=all_detections,\n",
    "        labels=labels)\n",
    "    annotated_frame = triangle_annotator.annotate(\n",
    "        scene=annotated_frame,\n",
    "        detections=ball_detections)\n",
    "\n",
    "    players_detections = sv.Detections.merge([\n",
    "        players_detections, goalkeepers_detections\n",
    "    ])\n",
    "\n",
    "    # detect pitch key points\n",
    "\n",
    "    result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "    key_points = sv.KeyPoints.from_inference(result)\n",
    "\n",
    "    # project ball, players and referies on pitch\n",
    "\n",
    "    filter = key_points.confidence[0] > 0.5\n",
    "    frame_reference_points = key_points.xy[0][filter]\n",
    "    pitch_reference_points = np.array(CONFIG.vertices)[filter]\n",
    "\n",
    "    transformer = ViewTransformer(\n",
    "        source=frame_reference_points,\n",
    "        target=pitch_reference_points\n",
    "    )\n",
    "\n",
    "    frame_ball_xy = ball_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "    pitch_ball_xy = transformer.transform_points(points=frame_ball_xy)\n",
    "\n",
    "    players_xy = players_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "    pitch_players_xy = transformer.transform_points(points=players_xy)\n",
    "\n",
    "    referees_xy = referees_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "    pitch_referees_xy = transformer.transform_points(points=referees_xy)\n",
    "\n",
    "    #sv.plot_image(annotated_frame)\n",
    "        \n",
    "    frames.append(annotated_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write position of everything detected on every frame\n",
    "print(frame_counter)\n",
    "\n",
    "#for i in range(0, frame_counter):\n",
    "    #sv.plot_image(frames[i])\n",
    "    \n",
    "#print position of everything detected on every frame\n",
    "print(f\"Frame {0}:\")\n",
    "#sv.plot_image(frames[0])\n",
    "       \n",
    "# Print positions of all detections\n",
    "# Convert detections.xyxy to xy positions and print them\n",
    "# Convert detections.xyxy to xy positions and print them\n",
    "for j, xyxy in enumerate(detections.xyxy):\n",
    "    x_min, y_min, x_max, y_max = xyxy  # Unpack bounding box coordinates\n",
    "    x_center = (x_min + x_max) / 2  # Calculate x center\n",
    "    y_center = (y_min + y_max) / 2  # Calculate y center\n",
    "    if detections.class_id[j] == BALL_ID:\n",
    "        print(f\"  Detection {j}: Center Position (x, y) = ({x_center}, {y_center})\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(detections.class_id.size):\n",
    " #   print(detections.class_id[i])\n",
    "\n",
    "for i in range(all_detections.class_id.size):\n",
    "    print(all_detections.class_id[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv.plot_image(frames[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, frame_counter):\n",
    "    print(f\"Frame {i}:\")\n",
    "    for j, xyxy in enumerate(detections.xyxy):\n",
    "        x_min, y_min, x_max, y_max = xyxy  # Unpack bounding box coordinates\n",
    "        x_center = (x_min + x_max) / 2  # Calculate x center\n",
    "        y_center = (y_min + y_max) / 2  # Calculate y center\n",
    "        if detections.class_id[j] == BALL_ID:\n",
    "            print(f\"  Detection {j}: Center Position (x, y) = ({x_center}, {y_center})\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Frame {frame_counter}: Total detections: {len(detections)}\")\n",
    "print(f\"Frame {frame_counter}: Total detections: {len(all_detections)}\")\n",
    "print(f\"Tracker IDs: {detections.tracker_id}\")\n",
    "\n",
    "print(f\"Frame {frame_counter}: Detection class IDs: {detections.class_id}\")\n",
    "print(f\"Frame {frame_counter}: Detection class IDs: {all_detections.class_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that saves each tenth frame of the video on a list \n",
    "#save position of each player and ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize video game-style radar view\n",
    "field_frames = []\n",
    "\n",
    "for i in range(frame_counter):\n",
    "    # draw pitch and players on pitch\n",
    "    annotated_frame = draw_pitch(CONFIG)\n",
    "    annotated_frame = draw_points_on_pitch(\n",
    "        config=CONFIG,\n",
    "        xy=pitch_ball_xy,\n",
    "        face_color=sv.Color.WHITE,\n",
    "        edge_color=sv.Color.BLACK,\n",
    "        radius=10,\n",
    "        pitch=annotated_frame)\n",
    "    annotated_frame = draw_points_on_pitch(\n",
    "        config=CONFIG,\n",
    "        xy=pitch_players_xy[players_detections.class_id == 0],\n",
    "        face_color=sv.Color.from_hex('00BFFF'),\n",
    "        edge_color=sv.Color.BLACK,\n",
    "        radius=16,\n",
    "        pitch=annotated_frame)\n",
    "    annotated_frame = draw_points_on_pitch(\n",
    "        config=CONFIG,\n",
    "        xy=pitch_players_xy[players_detections.class_id == 1],\n",
    "        face_color=sv.Color.from_hex('FF1493'),\n",
    "        edge_color=sv.Color.BLACK,\n",
    "        radius=16,\n",
    "        pitch=annotated_frame)\n",
    "    annotated_frame = draw_points_on_pitch(\n",
    "        config=CONFIG,\n",
    "        xy=pitch_referees_xy,\n",
    "        face_color=sv.Color.from_hex('FFD700'),\n",
    "        edge_color=sv.Color.BLACK,\n",
    "        radius=16,\n",
    "        pitch=annotated_frame)\n",
    "    \n",
    "    field_frames.append(annotated_frame)\n",
    "    \n",
    "sv.plot_image(field_frames[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Array of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "import cv2\n",
    "from sports.annotators.soccer import (\n",
    "    draw_pitch,\n",
    "    draw_points_on_pitch,\n",
    "    draw_pitch_voronoi_diagram\n",
    ")\n",
    "\n",
    "SOURCE_VIDEO_PATH = \"content/08fd33_4.mp4\"\n",
    "TARGET_VIDEO_PATH = \"content/08fd33_4_out.mp4\"\n",
    "BALL_ID = 0\n",
    "GOALKEEPER_ID = 1\n",
    "PLAYER_ID = 2\n",
    "REFEREE_ID = 3\n",
    "\n",
    "ellipse_annotator = sv.EllipseAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
    "    thickness=2\n",
    ")\n",
    "label_annotator = sv.LabelAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
    "    text_color=sv.Color.from_hex('#000000'),\n",
    "    text_position=sv.Position.BOTTOM_CENTER\n",
    ")\n",
    "triangle_annotator = sv.TriangleAnnotator(\n",
    "    color=sv.Color.from_hex('#FFD700'),\n",
    "    base=20, height=17\n",
    ")\n",
    "\n",
    "tracker = sv.ByteTrack()\n",
    "tracker.reset()\n",
    "\n",
    "frames_tracker = []\n",
    "field_frames = []\n",
    "frame_counter = 0\n",
    "stride = 10 #change to be faster\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "\n",
    "for frame_index, frame in enumerate(frame_generator):\n",
    "    if frame_index % stride != 0:\n",
    "        continue  # Skip frames that are not part of the stride\n",
    "\n",
    "    frame_counter += 1\n",
    "    \n",
    "    # ball, goalkeeper, player, referee detection\n",
    "\n",
    "    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "    detections = sv.Detections.from_inference(result)\n",
    "\n",
    "    ball_detections = detections[detections.class_id == BALL_ID]\n",
    "    ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
    "\n",
    "    all_detections = detections[detections.class_id != BALL_ID]\n",
    "    all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)\n",
    "    all_detections = tracker.update_with_detections(detections=all_detections)\n",
    "\n",
    "    goalkeepers_detections = all_detections[all_detections.class_id == GOALKEEPER_ID]\n",
    "    players_detections = all_detections[all_detections.class_id == PLAYER_ID]\n",
    "    referees_detections = all_detections[all_detections.class_id == REFEREE_ID]\n",
    "\n",
    "    # team assignment\n",
    "\n",
    "    players_crops = [sv.crop_image(frame, xyxy) for xyxy in players_detections.xyxy]\n",
    "    players_detections.class_id = team_classifier.predict(players_crops)\n",
    "\n",
    "    goalkeepers_detections.class_id = resolve_goalkeepers_team_id(\n",
    "        players_detections, goalkeepers_detections)\n",
    "\n",
    "    referees_detections.class_id -= 1\n",
    "\n",
    "    all_detections = sv.Detections.merge([\n",
    "        players_detections, goalkeepers_detections, referees_detections])\n",
    "\n",
    "    # frame visualization\n",
    "\n",
    "    labels = [\n",
    "        f\"#{tracker_id}\"\n",
    "        for tracker_id\n",
    "        in all_detections.tracker_id\n",
    "    ]\n",
    "\n",
    "    all_detections.class_id = all_detections.class_id.astype(int)\n",
    "\n",
    "    annotated_frame = frame.copy()\n",
    "    annotated_frame = ellipse_annotator.annotate(\n",
    "        scene=annotated_frame,\n",
    "        detections=all_detections)\n",
    "    annotated_frame = label_annotator.annotate(\n",
    "        scene=annotated_frame,\n",
    "        detections=all_detections,\n",
    "        labels=labels)\n",
    "    annotated_frame = triangle_annotator.annotate(\n",
    "        scene=annotated_frame,\n",
    "        detections=ball_detections)\n",
    "\n",
    "    frames_tracker.append(annotated_frame)\n",
    "    #sv.plot_image(annotated_frame)\n",
    "\n",
    "    players_detections = sv.Detections.merge([\n",
    "        players_detections, goalkeepers_detections\n",
    "    ])\n",
    "\n",
    "    # detect pitch key points\n",
    "\n",
    "    result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "    key_points = sv.KeyPoints.from_inference(result)\n",
    "\n",
    "    # project ball, players and referies on pitch\n",
    "\n",
    "    filter = key_points.confidence[0] > 0.5\n",
    "    frame_reference_points = key_points.xy[0][filter]\n",
    "    pitch_reference_points = np.array(CONFIG.vertices)[filter]\n",
    "\n",
    "    transformer = ViewTransformer(\n",
    "        source=frame_reference_points,\n",
    "        target=pitch_reference_points\n",
    "    )\n",
    "\n",
    "    frame_ball_xy = ball_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "    pitch_ball_xy = transformer.transform_points(points=frame_ball_xy)\n",
    "\n",
    "    players_xy = players_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "    pitch_players_xy = transformer.transform_points(points=players_xy)\n",
    "\n",
    "    referees_xy = referees_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "    pitch_referees_xy = transformer.transform_points(points=referees_xy)\n",
    "\n",
    "    # visualize video game-style radar view\n",
    "\n",
    "    annotated_frame = draw_pitch(CONFIG)\n",
    "    annotated_frame = draw_points_on_pitch(\n",
    "        config=CONFIG,\n",
    "        xy=pitch_ball_xy,\n",
    "        face_color=sv.Color.WHITE,\n",
    "        edge_color=sv.Color.BLACK,\n",
    "        radius=10,\n",
    "        pitch=annotated_frame)\n",
    "    annotated_frame = draw_points_on_pitch(\n",
    "        config=CONFIG,\n",
    "        xy=pitch_players_xy[players_detections.class_id == 0],\n",
    "        face_color=sv.Color.from_hex('00BFFF'),\n",
    "        edge_color=sv.Color.BLACK,\n",
    "        radius=16,\n",
    "        pitch=annotated_frame)\n",
    "    annotated_frame = draw_points_on_pitch(\n",
    "        config=CONFIG,\n",
    "        xy=pitch_players_xy[players_detections.class_id == 1],\n",
    "        face_color=sv.Color.from_hex('FF1493'),\n",
    "        edge_color=sv.Color.BLACK,\n",
    "        radius=16,\n",
    "        pitch=annotated_frame)\n",
    "    annotated_frame = draw_points_on_pitch(\n",
    "        config=CONFIG,\n",
    "        xy=pitch_referees_xy,\n",
    "        face_color=sv.Color.from_hex('FFD700'),\n",
    "        edge_color=sv.Color.BLACK,\n",
    "        radius=16,\n",
    "        pitch=annotated_frame)\n",
    "        \n",
    "    field_frames.append(annotated_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frame_counter)\n",
    "\n",
    "for i in range(0, frame_counter, 10):\n",
    "    \n",
    "    #sv.plot_image(frames_tracker[i])\n",
    "    sv.plot_image(field_frames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ball & player positions\n",
    "for i in range(0, frame_counter, 10):\n",
    "    print(f\"Frame {i}:\")\n",
    "    for j, xyxy in enumerate(detections.xyxy):\n",
    "        x_min, y_min, x_max, y_max = xyxy  # Unpack bounding box coordinates\n",
    "        x_center = (x_min + x_max) / 2  # Calculate x center\n",
    "        y_center = (y_min + y_max) / 2  # Calculate y center\n",
    "        if detections.class_id[j] == BALL_ID:\n",
    "            print(f\"  Detection {j}: Center Position (x, y) = ({x_center}, {y_center})\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 FRAME ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "import cv2\n",
    "from sports.annotators.soccer import (\n",
    "    draw_pitch,\n",
    "    draw_points_on_pitch,\n",
    "    draw_pitch_voronoi_diagram\n",
    ")\n",
    "\n",
    "SOURCE_VIDEO_PATH = \"content/08fd33_4.mp4\"\n",
    "TARGET_VIDEO_PATH = \"content/08fd33_4_out.mp4\"\n",
    "BALL_ID = 0\n",
    "GOALKEEPER_ID = 1\n",
    "PLAYER_ID = 2\n",
    "REFEREE_ID = 3\n",
    "\n",
    "ellipse_annotator = sv.EllipseAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
    "    thickness=2\n",
    ")\n",
    "label_annotator = sv.LabelAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
    "    text_color=sv.Color.from_hex('#000000'),\n",
    "    text_position=sv.Position.BOTTOM_CENTER\n",
    ")\n",
    "triangle_annotator = sv.TriangleAnnotator(\n",
    "    color=sv.Color.from_hex('#FFD700'),\n",
    "    base=20, height=17\n",
    ")\n",
    "\n",
    "tracker = sv.ByteTrack()\n",
    "tracker.reset()\n",
    "\n",
    "# Initialize an empty list to store frames\n",
    "frame_generator = []\n",
    "\n",
    "# Iterate through the frames generated by sv.get_video_frames_generator\n",
    "for frame in sv.get_video_frames_generator(SOURCE_VIDEO_PATH):\n",
    "    #only save every 10th frame\n",
    "    if len(frame_generator) % 10 == 0:\n",
    "        frame_generator.append(frame)  # Append each frame to the list\n",
    "\n",
    "# Print the total number of frames collected\n",
    "print(f\"Total frames collected: {len(frame_generator)}\")\n",
    "\n",
    "# ball, goalkeeper, player, referee detection\n",
    "result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "detections = sv.Detections.from_inference(result)\n",
    "\n",
    "ball_detections = detections[detections.class_id == BALL_ID]\n",
    "ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
    "\n",
    "all_detections = detections[detections.class_id != BALL_ID]\n",
    "all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)\n",
    "all_detections = tracker.update_with_detections(detections=all_detections)\n",
    "\n",
    "goalkeepers_detections = all_detections[all_detections.class_id == GOALKEEPER_ID]\n",
    "players_detections = all_detections[all_detections.class_id == PLAYER_ID]\n",
    "referees_detections = all_detections[all_detections.class_id == REFEREE_ID]\n",
    "\n",
    "# team assignment\n",
    "\n",
    "players_crops = [sv.crop_image(frame, xyxy) for xyxy in players_detections.xyxy]\n",
    "players_detections.class_id = team_classifier.predict(players_crops)\n",
    "\n",
    "goalkeepers_detections.class_id = resolve_goalkeepers_team_id(\n",
    "    players_detections, goalkeepers_detections)\n",
    "\n",
    "referees_detections.class_id -= 1\n",
    "\n",
    "all_detections = sv.Detections.merge([\n",
    "    players_detections, goalkeepers_detections, referees_detections])\n",
    "\n",
    "# frame visualization\n",
    "\n",
    "labels = [\n",
    "    f\"#{tracker_id}\"\n",
    "    for tracker_id\n",
    "    in all_detections.tracker_id\n",
    "]\n",
    "\n",
    "all_detections.class_id = all_detections.class_id.astype(int)\n",
    "\n",
    "annotated_frame = frame.copy()\n",
    "annotated_frame = ellipse_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    detections=all_detections)\n",
    "annotated_frame = label_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    detections=all_detections,\n",
    "    labels=labels)\n",
    "annotated_frame = triangle_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    detections=ball_detections)\n",
    "\n",
    "sv.plot_image(annotated_frame)\n",
    "\n",
    "players_detections = sv.Detections.merge([\n",
    "    players_detections, goalkeepers_detections\n",
    "])\n",
    "\n",
    "# detect pitch key points\n",
    "\n",
    "result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "key_points = sv.KeyPoints.from_inference(result)\n",
    "\n",
    "# project ball, players and referies on pitch\n",
    "\n",
    "filter = key_points.confidence[0] > 0.5\n",
    "frame_reference_points = key_points.xy[0][filter]\n",
    "pitch_reference_points = np.array(CONFIG.vertices)[filter]\n",
    "\n",
    "transformer = ViewTransformer(\n",
    "    source=frame_reference_points,\n",
    "    target=pitch_reference_points\n",
    ")\n",
    "\n",
    "frame_ball_xy = ball_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "pitch_ball_xy = transformer.transform_points(points=frame_ball_xy)\n",
    "\n",
    "players_xy = players_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "pitch_players_xy = transformer.transform_points(points=players_xy)\n",
    "\n",
    "referees_xy = referees_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "pitch_referees_xy = transformer.transform_points(points=referees_xy)\n",
    "\n",
    "# visualize video game-style radar view\n",
    "\n",
    "annotated_frame = draw_pitch(CONFIG)\n",
    "annotated_frame = draw_points_on_pitch(\n",
    "    config=CONFIG,\n",
    "    xy=pitch_ball_xy,\n",
    "    face_color=sv.Color.WHITE,\n",
    "    edge_color=sv.Color.BLACK,\n",
    "    radius=10,\n",
    "    pitch=annotated_frame)\n",
    "annotated_frame = draw_points_on_pitch(\n",
    "    config=CONFIG,\n",
    "    xy=pitch_players_xy[players_detections.class_id == 0],\n",
    "    face_color=sv.Color.from_hex('00BFFF'),\n",
    "    edge_color=sv.Color.BLACK,\n",
    "    radius=16,\n",
    "    pitch=annotated_frame)\n",
    "annotated_frame = draw_points_on_pitch(\n",
    "    config=CONFIG,\n",
    "    xy=pitch_players_xy[players_detections.class_id == 1],\n",
    "    face_color=sv.Color.from_hex('FF1493'),\n",
    "    edge_color=sv.Color.BLACK,\n",
    "    radius=16,\n",
    "    pitch=annotated_frame)\n",
    "annotated_frame = draw_points_on_pitch(\n",
    "    config=CONFIG,\n",
    "    xy=pitch_referees_xy,\n",
    "    face_color=sv.Color.from_hex('FFD700'),\n",
    "    edge_color=sv.Color.BLACK,\n",
    "    radius=16,\n",
    "    pitch=annotated_frame)\n",
    "    \n",
    "sv.plot_image(annotated_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "for frame_index, frame in enumerate(sv.get_video_frames_generator(SOURCE_VIDEO_PATH)):\n",
    "    if frame_index % 60 == 0:  # Save only every 10th frame\n",
    "        frames.append(frame)\n",
    "\n",
    "print(f\"Total frames collected: {len(frames)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_View_frames = []\n",
    "virtField_View_frames = []\n",
    "frame_counter = 1\n",
    "tracker = sv.ByteTrack()\n",
    "\n",
    "for frame in frames:\n",
    "    print(f\"Processing frame {frame_counter}...\")\n",
    "    frame_counter += 1\n",
    "    \n",
    "    # ball, goalkeeper, player, referee detection\n",
    "    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "    detections = sv.Detections.from_inference(result)\n",
    "\n",
    "    ball_detections = detections[detections.class_id == BALL_ID]\n",
    "    ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
    "\n",
    "    all_detections = detections[detections.class_id != BALL_ID]\n",
    "    all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)\n",
    "    all_detections = tracker.update_with_detections(detections=all_detections)\n",
    "\n",
    "    goalkeepers_detections = all_detections[all_detections.class_id == GOALKEEPER_ID]\n",
    "    players_detections = all_detections[all_detections.class_id == PLAYER_ID]\n",
    "    referees_detections = all_detections[all_detections.class_id == REFEREE_ID]\n",
    "\n",
    "    # team assignment\n",
    "    players_crops = [sv.crop_image(frame, xyxy) for xyxy in players_detections.xyxy]\n",
    "    players_detections.class_id = team_classifier.predict(players_crops)\n",
    "\n",
    "    goalkeepers_detections.class_id = resolve_goalkeepers_team_id(\n",
    "        players_detections, goalkeepers_detections)\n",
    "\n",
    "    referees_detections.class_id -= 1\n",
    "\n",
    "    all_detections = sv.Detections.merge([\n",
    "        players_detections, goalkeepers_detections, referees_detections])\n",
    "\n",
    "    # frame visualization\n",
    "    labels = [\n",
    "        f\"#{tracker_id}\"\n",
    "        for tracker_id\n",
    "        in all_detections.tracker_id\n",
    "    ]\n",
    "\n",
    "    all_detections.class_id = all_detections.class_id.astype(int)\n",
    "\n",
    "    annotated_frame = frame.copy()\n",
    "    annotated_frame = ellipse_annotator.annotate(\n",
    "        scene=annotated_frame,\n",
    "        detections=all_detections)\n",
    "    annotated_frame = label_annotator.annotate(\n",
    "        scene=annotated_frame,\n",
    "        detections=all_detections,\n",
    "        labels=labels)\n",
    "    annotated_frame = triangle_annotator.annotate(\n",
    "        scene=annotated_frame,\n",
    "        detections=ball_detections)\n",
    "\n",
    "    field_View_frames.append(annotated_frame)\n",
    "    #sv.plot_image(annotated_frame)\n",
    "\n",
    "    players_detections = sv.Detections.merge([\n",
    "        players_detections, goalkeepers_detections\n",
    "    ])\n",
    "\n",
    "    # detect pitch key points\n",
    "    result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "    key_points = sv.KeyPoints.from_inference(result)\n",
    "\n",
    "    # project ball, players and referies on pitch\n",
    "    filter = key_points.confidence[0] > 0.5\n",
    "    frame_reference_points = key_points.xy[0][filter]\n",
    "    pitch_reference_points = np.array(CONFIG.vertices)[filter]\n",
    "\n",
    "    transformer = ViewTransformer(\n",
    "        source=frame_reference_points,\n",
    "        target=pitch_reference_points\n",
    "    )\n",
    "\n",
    "    frame_ball_xy = ball_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "    pitch_ball_xy = transformer.transform_points(points=frame_ball_xy)\n",
    "\n",
    "    players_xy = players_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "    pitch_players_xy = transformer.transform_points(points=players_xy)\n",
    "\n",
    "    referees_xy = referees_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "    pitch_referees_xy = transformer.transform_points(points=referees_xy)\n",
    "\n",
    "    # visualize video game-style radar view\n",
    "    annotated_frame = draw_pitch(CONFIG)\n",
    "    annotated_frame = draw_points_on_pitch(\n",
    "        config=CONFIG,\n",
    "        xy=pitch_ball_xy,\n",
    "        face_color=sv.Color.WHITE,\n",
    "        edge_color=sv.Color.BLACK,\n",
    "        radius=10,\n",
    "        pitch=annotated_frame)\n",
    "    annotated_frame = draw_points_on_pitch(\n",
    "        config=CONFIG,\n",
    "        xy=pitch_players_xy[players_detections.class_id == 0],\n",
    "        face_color=sv.Color.from_hex('00BFFF'),\n",
    "        edge_color=sv.Color.BLACK,\n",
    "        radius=16,\n",
    "        pitch=annotated_frame)\n",
    "    annotated_frame = draw_points_on_pitch(\n",
    "        config=CONFIG,\n",
    "        xy=pitch_players_xy[players_detections.class_id == 1],\n",
    "        face_color=sv.Color.from_hex('FF1493'),\n",
    "        edge_color=sv.Color.BLACK,\n",
    "        radius=16,\n",
    "        pitch=annotated_frame)\n",
    "    annotated_frame = draw_points_on_pitch(\n",
    "        config=CONFIG,\n",
    "        xy=pitch_referees_xy,\n",
    "        face_color=sv.Color.from_hex('FFD700'),\n",
    "        edge_color=sv.Color.BLACK,\n",
    "        radius=16,\n",
    "        pitch=annotated_frame)\n",
    "        \n",
    "    virtField_View_frames.append(annotated_frame)\n",
    "    \n",
    "    tracker.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'field_View_frames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#loop created frames\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mfield_View_frames\u001b[49m)):\n\u001b[0;32m      3\u001b[0m     sv\u001b[38;5;241m.\u001b[39mplot_image(field_View_frames[i])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'field_View_frames' is not defined"
     ]
    }
   ],
   "source": [
    "#loop created frames\n",
    "for i in range(0, len(field_View_frames)):\n",
    "    #sv.plot_image(field_View_frames[i])\n",
    "    sv.plot_image(virtField_View_frames[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
