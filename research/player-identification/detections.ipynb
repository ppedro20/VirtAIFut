{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"ONNXRUNTIME_EXECUTION_PROVIDERS\"] = \"[CUDAExecutionProvider]\"\n",
    "\n",
    "from inference import get_model\n",
    "\n",
    "ROBOFLOW_API_KEY = 'tCy476DHnSoq6mwGtVpp'\n",
    "PLAYER_DETECTION_MODEL_ID = 'football-players-detection-3zvbc/2'\n",
    "PLAYER_DETECTION_MODEL = get_model(PLAYER_DETECTION_MODEL_ID, ROBOFLOW_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_VIDEO_PATH = \"../data/videos/new.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "from tqdm import tqdm\n",
    "\n",
    "annotated_frames = []\n",
    "\n",
    "box_annotator = sv.BoxAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(['#FF8C00', '#00BFFF', '#FF1493', '#FFD700']),\n",
    "    thickness=2\n",
    ")\n",
    "label_annotator = sv.LabelAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(['#FF8C00', '#00BFFF', '#FF1493', '#FFD700']),\n",
    "    text_color=sv.Color.from_hex('#000000')\n",
    ")\n",
    "'''\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "frame = next(frame_generator)'''\n",
    "\n",
    "for frame_index, frame in enumerate(tqdm(frames, desc=\"Processing...\")):\n",
    "    tqdm.write(f\"Frame {frame_index}\")\n",
    "\n",
    "    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.7)[0]\n",
    "    detections = sv.Detections.from_inference(result)\n",
    "\n",
    "    labels = [\n",
    "        f\"{class_name} {confidence:.2f}\"\n",
    "        for class_name, confidence\n",
    "        in zip(detections['class_name'], detections.confidence)\n",
    "    ]\n",
    "\n",
    "    annotated_frame = frame.copy()\n",
    "    annotated_frame = box_annotator.annotate(\n",
    "        scene=annotated_frame,\n",
    "        detections=detections)\n",
    "    annotated_frame = label_annotator.annotate(\n",
    "        scene=annotated_frame,\n",
    "        detections=detections,\n",
    "        labels=labels)\n",
    "\n",
    "    annotated_frames.append(annotated_frame)\n",
    "    #sv.plot_image(annotated_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "\n",
    "BALL_ID = 0\n",
    "\n",
    "ellipse_annotator = sv.EllipseAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
    "    thickness=2\n",
    ")\n",
    "triangle_annotator = sv.TriangleAnnotator(\n",
    "    color=sv.Color.from_hex('#FFD700'),\n",
    "    base=25,\n",
    "    height=21,\n",
    "    outline_thickness=1\n",
    ")\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "frame = next(frame_generator)\n",
    "\n",
    "result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "detections = sv.Detections.from_inference(result)\n",
    "\n",
    "ball_detections = detections[detections.class_id == BALL_ID]\n",
    "ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
    "\n",
    "all_detections = detections[detections.class_id != BALL_ID]\n",
    "all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)\n",
    "all_detections.class_id -= 1\n",
    "\n",
    "annotated_frame = frame.copy()\n",
    "annotated_frame = ellipse_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    detections=all_detections)\n",
    "annotated_frame = triangle_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    detections=ball_detections)\n",
    "\n",
    "sv.plot_image(annotated_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "\n",
    "BALL_ID = 0\n",
    "\n",
    "ellipse_annotator = sv.EllipseAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
    "    thickness=2\n",
    ")\n",
    "label_annotator = sv.LabelAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
    "    text_color=sv.Color.from_hex('#000000'),\n",
    "    text_position=sv.Position.BOTTOM_CENTER\n",
    ")\n",
    "triangle_annotator = sv.TriangleAnnotator(\n",
    "    color=sv.Color.from_hex('#FFD700'),\n",
    "    base=25,\n",
    "    height=21,\n",
    "    outline_thickness=1\n",
    ")\n",
    "\n",
    "tracker = sv.ByteTrack()\n",
    "tracker.reset()\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "frame = next(frame_generator)\n",
    "\n",
    "result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "detections = sv.Detections.from_inference(result)\n",
    "\n",
    "ball_detections = detections[detections.class_id == BALL_ID]\n",
    "ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
    "\n",
    "all_detections = detections[detections.class_id != BALL_ID]\n",
    "all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)\n",
    "all_detections.class_id -= 1\n",
    "all_detections = tracker.update_with_detections(detections=all_detections)\n",
    "\n",
    "labels = [\n",
    "    f\"#{tracker_id}\"\n",
    "    for tracker_id\n",
    "    in all_detections.tracker_id\n",
    "]\n",
    "\n",
    "annotated_frame = frame.copy()\n",
    "annotated_frame = ellipse_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    detections=all_detections)\n",
    "annotated_frame = label_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    detections=all_detections,\n",
    "    labels=labels)\n",
    "annotated_frame = triangle_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    detections=ball_detections)\n",
    "\n",
    "sv.plot_image(annotated_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split players into teams with siglip, umap and kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop up players by their bounding boxes\n",
    "from tqdm import tqdm\n",
    "\n",
    "#SOURCE_VIDEO_PATH = \"../data/videos/new.mp4\"\n",
    "PLAYER_ID = 2\n",
    "STRIDE = 30\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(\n",
    "    source_path=SOURCE_VIDEO_PATH, stride=STRIDE)\n",
    "\n",
    "crops = []\n",
    "for frame in tqdm(frame_generator, desc='collecting crops'):\n",
    "    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.5)[0]\n",
    "    detections = sv.Detections.from_inference(result)\n",
    "    detections = detections.with_nms(threshold=0.5, class_agnostic=True)\n",
    "    detections = detections[detections.class_id == PLAYER_ID]\n",
    "    players_crops = [sv.crop_image(frame, xyxy) for xyxy in detections.xyxy]\n",
    "    crops += players_crops\n",
    " \n",
    "#Note: Here's a sample (100 elements) of the crops we've gathered.   \n",
    "sv.plot_images_grid(crops[:100], grid_size=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: Next, we'll run SigLIP to calculate embeddings for each of the crops.\n",
    "import torch\n",
    "from transformers import AutoProcessor, SiglipVisionModel\n",
    "\n",
    "SIGLIP_MODEL_PATH = 'google/siglip-base-patch16-224'\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "EMBEDDINGS_MODEL = SiglipVisionModel.from_pretrained(SIGLIP_MODEL_PATH).to(DEVICE)\n",
    "EMBEDDINGS_PROCESSOR = AutoProcessor.from_pretrained(SIGLIP_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code performs batch processing of image crops to extract embeddings (numerical representations) using a deep learning model\n",
    "import numpy as np\n",
    "from more_itertools import chunked\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "crops = [sv.cv2_to_pillow(crop) for crop in crops]\n",
    "batches = chunked(crops, BATCH_SIZE)\n",
    "data = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(batches, desc='embedding extraction'):\n",
    "        inputs = EMBEDDINGS_PROCESSOR(images=batch, return_tensors=\"pt\").to(DEVICE)\n",
    "        outputs = EMBEDDINGS_MODEL(**inputs)\n",
    "        embeddings = torch.mean(outputs.last_hidden_state, dim=1).cpu().numpy()\n",
    "        data.append(embeddings)\n",
    "\n",
    "data = np.concatenate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: Using UMAP, we project our embeddings from (N, 768) to (N, 3) and then perform a two-cluster division using KMeans.\n",
    "import umap\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "REDUCER = umap.UMAP(n_components=3)\n",
    "CLUSTERING_MODEL = KMeans(n_clusters=2)\n",
    "\n",
    "projections = REDUCER.fit_transform(data)\n",
    "clusters = CLUSTERING_MODEL.fit_predict(projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "from tqdm import tqdm\n",
    "from sports.common.team import TeamClassifier\n",
    "\n",
    "#SOURCE_VIDEO_PATH = \"../data/videos/new.mp4\"\n",
    "PLAYER_ID = 2\n",
    "STRIDE = 30\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(\n",
    "    source_path=SOURCE_VIDEO_PATH, stride=STRIDE)\n",
    "\n",
    "crops = []\n",
    "for frame in tqdm(frame_generator, desc='collecting crops'):\n",
    "    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "    detections = sv.Detections.from_inference(result)\n",
    "    players_detections = detections[detections.class_id == PLAYER_ID]\n",
    "    players_crops = [sv.crop_image(frame, xyxy) for xyxy in detections.xyxy]\n",
    "    crops += players_crops\n",
    "\n",
    "team_classifier = TeamClassifier(device=\"cpu\")\n",
    "team_classifier.fit(crops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import supervision as sv\n",
    "\n",
    "GK_TEAM_1_ID = 1\n",
    "GK_TEAM_2_ID = 12\n",
    "\n",
    "def resolve_goalkeepers_team_id(\n",
    "    players: sv.Detections,\n",
    "    goalkeepers: sv.Detections\n",
    ") -> np.ndarray:\n",
    "    goalkeepers_xy = goalkeepers.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "    players_xy = players.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "    \n",
    "    # Check if players exist for each team\n",
    "    if np.any(players.class_id == 0):\n",
    "        team_0_centroid = players_xy[players.class_id == 0].mean(axis=0)\n",
    "    else:\n",
    "        team_0_centroid = np.array([np.inf, np.inf])  # Default value if no players for team 0\n",
    "\n",
    "    if np.any(players.class_id == 1):\n",
    "        team_1_centroid = players_xy[players.class_id == 1].mean(axis=0)\n",
    "    else:\n",
    "        team_1_centroid = np.array([np.inf, np.inf])  # Default value if no players for team 1\n",
    "\n",
    "    goalkeepers_team_id = []\n",
    "    assigned_teams = set()  # Track assigned teams to avoid duplicates\n",
    "\n",
    "    for goalkeeper_xy in goalkeepers_xy:\n",
    "        dist_0 = np.linalg.norm(goalkeeper_xy - team_0_centroid)\n",
    "        dist_1 = np.linalg.norm(goalkeeper_xy - team_1_centroid)\n",
    "        \n",
    "        if dist_0 < dist_1 and 0 not in assigned_teams:\n",
    "            goalkeepers_team_id.append(GK_TEAM_1_ID)\n",
    "            assigned_teams.add(0)\n",
    "        elif dist_1 <= dist_0 and 1 not in assigned_teams:\n",
    "            goalkeepers_team_id.append(GK_TEAM_2_ID)\n",
    "            assigned_teams.add(1)\n",
    "        else:\n",
    "            # Assign to the closest team if both teams are already assigned\n",
    "            goalkeepers_team_id.append(GK_TEAM_1_ID if dist_0 < dist_1 else GK_TEAM_2_ID)\n",
    "\n",
    "    return np.array(goalkeepers_team_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#team assignment and goalkeepers team assignment working together\n",
    "import supervision as sv\n",
    "\n",
    "#SOURCE_VIDEO_PATH = \"../data/videos/new.mp4\"\n",
    "BALL_ID = 0\n",
    "GOALKEEPER_ID = 1\n",
    "PLAYER_ID = 2\n",
    "REFEREE_ID = 3\n",
    "\n",
    "ellipse_annotator = sv.EllipseAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
    "    thickness=2\n",
    ")\n",
    "label_annotator = sv.LabelAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
    "    text_color=sv.Color.from_hex('#000000'),\n",
    "    text_position=sv.Position.BOTTOM_CENTER\n",
    ")\n",
    "triangle_annotator = sv.TriangleAnnotator(\n",
    "    color=sv.Color.from_hex('#FFD700'),\n",
    "    base=25,\n",
    "    height=21,\n",
    "    outline_thickness=1\n",
    ")\n",
    "\n",
    "tracker = sv.ByteTrack()\n",
    "tracker.reset()\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "frame = next(frame_generator)\n",
    "\n",
    "result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "detections = sv.Detections.from_inference(result)\n",
    "\n",
    "ball_detections = detections[detections.class_id == BALL_ID]\n",
    "ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
    "\n",
    "all_detections = detections[detections.class_id != BALL_ID]\n",
    "all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)\n",
    "all_detections = tracker.update_with_detections(detections=all_detections)\n",
    "\n",
    "goalkeepers_detections = all_detections[all_detections.class_id == GOALKEEPER_ID]\n",
    "players_detections = all_detections[all_detections.class_id == PLAYER_ID]\n",
    "\n",
    "players_crops = [sv.crop_image(frame, xyxy) for xyxy in players_detections.xyxy]\n",
    "players_detections.class_id = team_classifier.predict(players_crops)\n",
    "\n",
    "goalkeepers_detections.class_id = resolve_goalkeepers_team_id(\n",
    "    players_detections, goalkeepers_detections)\n",
    "\n",
    "all_detections = sv.Detections.merge([\n",
    "    players_detections, goalkeepers_detections])\n",
    "\n",
    "labels = [\n",
    "    f\"#{tracker_id} (GK)\" if class_id in [GK_TEAM_1_ID, GK_TEAM_2_ID] else f\"#{tracker_id}\"\n",
    "    for tracker_id, class_id in zip(all_detections.tracker_id, all_detections.class_id)\n",
    "]\n",
    "\n",
    "all_detections.class_id = all_detections.class_id.astype(int)\n",
    "annotated_frame = frame.copy()\n",
    "annotated_frame = ellipse_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    detections=all_detections)\n",
    "annotated_frame = label_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    detections=all_detections,\n",
    "    labels=labels)\n",
    "annotated_frame = triangle_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    detections=ball_detections)\n",
    "\n",
    "sv.plot_image(annotated_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KEYPOINTS SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import get_model\n",
    "\n",
    "ROBOFLOW_API_KEY = 'tCy476DHnSoq6mwGtVpp'\n",
    "FIELD_DETECTION_MODEL_ID = \"football-field-detection-f07vi/14\"\n",
    "FIELD_DETECTION_MODEL = get_model(model_id=FIELD_DETECTION_MODEL_ID, api_key=ROBOFLOW_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "\n",
    "#SOURCE_VIDEO_PATH = \"../data/videos/new.mp4\"\n",
    "\n",
    "vertex_annotator = sv.VertexAnnotator(\n",
    "    color=sv.Color.from_hex('#FF1493'),\n",
    "    radius=8)\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "frame = next(frame_generator)\n",
    "\n",
    "result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "key_points = sv.KeyPoints.from_inference(result)\n",
    "\n",
    "annotated_frame = frame.copy()\n",
    "annotated_frame = vertex_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    key_points=key_points)\n",
    "\n",
    "sv.plot_image(annotated_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter low confidence keypoints\n",
    "import supervision as sv\n",
    "import numpy as np\n",
    "\n",
    "#SOURCE_VIDEO_PATH = \"../data/videos/new.mp4\"\n",
    "\n",
    "vertex_annotator = sv.VertexAnnotator(\n",
    "    color=sv.Color.from_hex('#FF1493'),\n",
    "    radius=8)\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "frame = next(frame_generator)\n",
    "\n",
    "result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "key_points = sv.KeyPoints.from_inference(result)\n",
    "\n",
    "filter = key_points.confidence[0] > 0.5\n",
    "frame_reference_points = key_points.xy[0][filter]\n",
    "frame_reference_key_points = sv.KeyPoints(\n",
    "    xy=frame_reference_points[np.newaxis, ...])\n",
    "\n",
    "annotated_frame = frame.copy()\n",
    "annotated_frame = vertex_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    key_points=frame_reference_key_points)\n",
    "\n",
    "sv.plot_image(annotated_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "project pitch lines on frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sports.annotators.soccer import draw_pitch\n",
    "from sports.configs.soccer import SoccerPitchConfiguration\n",
    "\n",
    "CONFIG = SoccerPitchConfiguration()\n",
    "\n",
    "annotated_frame = draw_pitch(CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import supervision as sv\n",
    "from sports.common.view import ViewTransformer\n",
    "\n",
    "#SOURCE_VIDEO_PATH = \"../data/videos/new.mp4\"\n",
    "\n",
    "edge_annotator = sv.EdgeAnnotator(\n",
    "    color=sv.Color.from_hex('#00BFFF'),\n",
    "    thickness=2, edges=CONFIG.edges)\n",
    "vertex_annotator = sv.VertexAnnotator(\n",
    "    color=sv.Color.from_hex('#FF1493'),\n",
    "    radius=8)\n",
    "vertex_annotator_2 = sv.VertexAnnotator(\n",
    "    color=sv.Color.from_hex('#00BFFF'),\n",
    "    radius=8)\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH, start=200)\n",
    "frame = next(frame_generator)\n",
    "\n",
    "result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "key_points = sv.KeyPoints.from_inference(result)\n",
    "\n",
    "filter = key_points.confidence[0] > 0.5\n",
    "frame_reference_points = key_points.xy[0][filter]\n",
    "frame_reference_key_points = sv.KeyPoints(\n",
    "    xy=frame_reference_points[np.newaxis, ...])\n",
    "\n",
    "pitch_reference_points = np.array(CONFIG.vertices)[filter]\n",
    "\n",
    "transformer = ViewTransformer(\n",
    "    source=pitch_reference_points,\n",
    "    target=frame_reference_points\n",
    ")\n",
    "\n",
    "pitch_all_points = np.array(CONFIG.vertices)\n",
    "frame_all_points = transformer.transform_points(points=pitch_all_points)\n",
    "\n",
    "frame_all_key_points = sv.KeyPoints(xy=frame_all_points[np.newaxis, ...])\n",
    "\n",
    "annotated_frame = frame.copy()\n",
    "annotated_frame = edge_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    key_points=frame_all_key_points)\n",
    "annotated_frame = vertex_annotator_2.annotate(\n",
    "    scene=annotated_frame,\n",
    "    key_points=frame_all_key_points)\n",
    "annotated_frame = vertex_annotator.annotate(\n",
    "    scene=annotated_frame,\n",
    "    key_points=frame_reference_key_points)\n",
    "\n",
    "sv.plot_image(annotated_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "project ball, players and referies on pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "from tqdm import tqdm\n",
    "from sports.common.team import TeamClassifier\n",
    "\n",
    "#SOURCE_VIDEO_PATH = \"../data/videos/new.mp4\"\n",
    "PLAYER_ID = 2\n",
    "STRIDE = 30\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(\n",
    "    source_path=SOURCE_VIDEO_PATH, stride=STRIDE)\n",
    "\n",
    "crops = []\n",
    "for frame in tqdm(frame_generator, desc='collecting crops'):\n",
    "    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "    detections = sv.Detections.from_inference(result)\n",
    "    players_detections = detections[detections.class_id == PLAYER_ID]\n",
    "    players_crops = [sv.crop_image(frame, xyxy) for xyxy in detections.xyxy]\n",
    "    crops += players_crops\n",
    "\n",
    "team_classifier = TeamClassifier(device=\"cpu\")\n",
    "team_classifier.fit(crops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "for frame_index, frame in enumerate(sv.get_video_frames_generator(SOURCE_VIDEO_PATH)):\n",
    "    if frame_index % 10 == 0:  # Save only every 10th frame\n",
    "        frames.append(frame)\n",
    "\n",
    "print(f\"Total frames collected: {len(frames)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "import cv2\n",
    "from sports.annotators.soccer import (\n",
    "    draw_pitch,\n",
    "    draw_points_on_pitch\n",
    ")\n",
    "\n",
    "field_View_frames = []\n",
    "\n",
    "ball_positions = []\n",
    "gk_positions = []\n",
    "\n",
    "gk_team_1_positions = []\n",
    "gk_team_2_positions = []\n",
    "\n",
    "tracker = sv.ByteTrack()\n",
    "frame_counter = 0\n",
    "\n",
    "for frame_index, frame in enumerate(tqdm(frames, desc=\"Processing...\")):\n",
    "    tqdm.write(f\"Frame {frame_index}\")\n",
    "        \n",
    "    # ball, goalkeeper, player, referee detection\n",
    "    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "    detections = sv.Detections.from_inference(result)\n",
    "\n",
    "    ball_detections = detections[detections.class_id == BALL_ID]\n",
    "    ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
    "    \n",
    "    if len(ball_detections.xyxy) > 0:\n",
    "        x_min, y_min, x_max, y_max = ball_detections.xyxy[0]  # Assuming one ball per frame\n",
    "        x_center = (x_min + x_max) / 2\n",
    "        y_center = (y_min + y_max) / 2\n",
    "        ball_positions.append((frame_index, x_center, y_center))\n",
    "    else:\n",
    "        ball_positions.append((frame_index, None, None))  # No ball detected in this frame\n",
    "\n",
    "    all_detections = detections[detections.class_id != BALL_ID]\n",
    "    all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)\n",
    "    all_detections = tracker.update_with_detections(detections=all_detections)\n",
    "\n",
    "    goalkeepers_detections = all_detections[all_detections.class_id == GOALKEEPER_ID]\n",
    "    \n",
    "    # Assign teams to goalkeepers\n",
    "    goalkeepers_detections.class_id = resolve_goalkeepers_team_id(players_detections, goalkeepers_detections)\n",
    "    \n",
    "    # Track goalkeeper positions\n",
    "    # Ensure positions are appended correctly for both goalkeepers\n",
    "    #gk 1\n",
    "    for gk_xyxy, gk_class_id in zip(goalkeepers_detections.xyxy, goalkeepers_detections.class_id):\n",
    "        x_min, y_min, x_max, y_max = gk_xyxy\n",
    "        x_center = (x_min + x_max) / 2\n",
    "        y_center = (y_min + y_max) / 2\n",
    "\n",
    "        if gk_class_id == GK_TEAM_1_ID:\n",
    "            gk_team_1_positions.append((frame_index, x_center, y_center))\n",
    "        else:\n",
    "            gk_team_1_positions.append((frame_index, None, None))    \n",
    "    \n",
    "    #gk 2\n",
    "    for gk_xyxy, gk_class_id in zip(goalkeepers_detections.xyxy, goalkeepers_detections.class_id):\n",
    "        x_min, y_min, x_max, y_max = gk_xyxy\n",
    "        x_center = (x_min + x_max) / 2\n",
    "        y_center = (y_min + y_max) / 2\n",
    "        \n",
    "        if gk_class_id == GK_TEAM_2_ID:\n",
    "            gk_team_2_positions.append((frame_index, x_center, y_center))\n",
    "        else:\n",
    "            gk_team_2_positions.append((frame_index, None, None)) \n",
    "    \n",
    "    players_detections = all_detections[all_detections.class_id == PLAYER_ID]\n",
    "\n",
    "    # team assignment\n",
    "    players_crops = [sv.crop_image(frame, xyxy) for xyxy in players_detections.xyxy]\n",
    "    players_detections.class_id = team_classifier.predict(players_crops)\n",
    "\n",
    "    goalkeepers_detections.class_id = resolve_goalkeepers_team_id(\n",
    "        players_detections, goalkeepers_detections)\n",
    "\n",
    "    all_detections = sv.Detections.merge([\n",
    "        players_detections, goalkeepers_detections])\n",
    "\n",
    "    # frame visualization\n",
    "    labels = [\n",
    "    f\"#{tracker_id} (GK)\" if class_id in [GK_TEAM_1_ID, GK_TEAM_2_ID] else f\"#{tracker_id}\"\n",
    "    for tracker_id, class_id in zip(all_detections.tracker_id, all_detections.class_id)\n",
    "    ]\n",
    "\n",
    "    all_detections.class_id = all_detections.class_id.astype(int)\n",
    "\n",
    "    annotated_frame = frame.copy()\n",
    "    annotated_frame = ellipse_annotator.annotate(\n",
    "        scene=annotated_frame,\n",
    "        detections=all_detections)\n",
    "    annotated_frame = label_annotator.annotate(\n",
    "        scene=annotated_frame,\n",
    "        detections=all_detections,\n",
    "        labels=labels)\n",
    "    annotated_frame = triangle_annotator.annotate(\n",
    "        scene=annotated_frame,\n",
    "        detections=ball_detections)\n",
    "\n",
    "    field_View_frames.append(annotated_frame)\n",
    "    #sv.plot_image(annotated_frame)\n",
    "\n",
    "    players_detections = sv.Detections.merge([\n",
    "        players_detections, goalkeepers_detections\n",
    "    ])\n",
    "\n",
    "    # detect pitch key points\n",
    "    result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "    key_points = sv.KeyPoints.from_inference(result)\n",
    "\n",
    "    # project ball, players on pitch\n",
    "    filter = key_points.confidence[0] > 0.5\n",
    "    frame_reference_points = key_points.xy[0][filter]\n",
    "    pitch_reference_points = np.array(CONFIG.vertices)[filter]\n",
    "\n",
    "    transformer = ViewTransformer(\n",
    "        source=frame_reference_points,\n",
    "        target=pitch_reference_points\n",
    "    )\n",
    "\n",
    "    frame_ball_xy = ball_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "    pitch_ball_xy = transformer.transform_points(points=frame_ball_xy)\n",
    "\n",
    "    players_xy = players_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "    pitch_players_xy = transformer.transform_points(points=players_xy)\n",
    "\n",
    "    tracker.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through ball positions and goalkeeper positions\n",
    "for (frame_index, ball_x, ball_y) in ball_positions:\n",
    "    # Get the goalkeeper positions for the current frame\n",
    "    gk_team_1_position = next((pos for pos in gk_team_1_positions if pos[0] == frame_index), None)\n",
    "    gk_team_2_position = next((pos for pos in gk_team_2_positions if pos[0] == frame_index), None)\n",
    "\n",
    "    # Print ball position\n",
    "    print(f\"Frame {frame_index}: Ball ({ball_x}, {ball_y})\")\n",
    "\n",
    "    # Print goalkeeper positions\n",
    "    if gk_team_1_position:\n",
    "        print(f\"Frame {frame_index}: GK Team 1 Position: ({gk_team_1_position[1]}, {gk_team_1_position[2]})\")\n",
    "    else:\n",
    "        print(f\"Frame {frame_index}: GK Team 1 Position: None\")\n",
    "\n",
    "    if gk_team_2_position:\n",
    "        print(f\"Frame {frame_index}: GK Team 2 Position: ({gk_team_2_position[1]}, {gk_team_2_position[2]})\")\n",
    "    else:\n",
    "        print(f\"Frame {frame_index}: GK Team 2 Position: None\")\n",
    "        \n",
    "    sv.plot_image(field_View_frames[frame_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save array as csv\n",
    "import numpy as np\n",
    "\n",
    "np.savetxt(\"../data/raw/ball_positions.csv\", ball_positions, delimiter=\",\", header=\"Frame, ball_x, ball_y\", comments='',fmt='%s')\n",
    "np.savetxt(\"../data/raw/gk_1_positions.csv\", gk_team_1_positions, delimiter=\",\", header=\"Frame, gk1_x, gk1_y\", comments='',fmt='%s')\n",
    "np.savetxt(\"../data/raw/gk_2_positions.csv\", gk_team_2_positions, delimiter=\",\", header=\"Frame, gk2_x, gk2_y\", comments='',fmt='%s')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
