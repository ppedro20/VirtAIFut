{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85a1fbf1",
   "metadata": {},
   "source": [
    "02. DETECTIONS TRACKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "327cf98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"ONNXRUNTIME_EXECUTION_PROVIDERS\"] = \"[CUDAExecutionProvider]\"\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.getenv(\"PROJECT_PATH\"))\n",
    "\n",
    "from inference import get_model\n",
    "import supervision as sv\n",
    "\n",
    "ROBOFLOW_API_KEY = os.getenv(\"ROBOFLOW_API_KEY\")\n",
    "\n",
    "PLAYER_DETECTION_MODEL_ID = 'football-players-detection-3zvbc/2'\n",
    "PLAYER_DETECTION_MODEL = get_model(PLAYER_DETECTION_MODEL_ID, ROBOFLOW_API_KEY)\n",
    "\n",
    "FIELD_DETECTION_MODEL_ID = \"football-field-detection-f07vi/14\"\n",
    "FIELD_DETECTION_MODEL = get_model(model_id=FIELD_DETECTION_MODEL_ID, api_key=ROBOFLOW_API_KEY)\n",
    "\n",
    "SOURCE_VIDEO_PATH = \"../../data/videos/new5s.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "425f1626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Supervision annotators\n",
    "from utils.pitchconfig import SoccerPitchConfiguration\n",
    "\n",
    "CONFIG = SoccerPitchConfiguration()\n",
    "\n",
    "ellipse_annotator = sv.EllipseAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']), #blue, pink, yellow\n",
    "    thickness=2\n",
    ")\n",
    "label_annotator = sv.LabelAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']), #blue, pink, yellow\n",
    "    text_color=sv.Color.from_hex('#000000'),\n",
    "    text_position=sv.Position.BOTTOM_CENTER\n",
    ")\n",
    "triangle_annotator = sv.TriangleAnnotator(\n",
    "    color=sv.Color.from_hex('#FFD700'),\n",
    "    base=25,\n",
    "    height=21,\n",
    "    outline_thickness=1\n",
    ")\n",
    "\n",
    "#Supervision - virtualization\n",
    "edge_annotator = sv.EdgeAnnotator(\n",
    "    color=sv.Color.from_hex('#00BFFF'),\n",
    "    thickness=2, edges=CONFIG.edges)\n",
    "vertex_annotator = sv.VertexAnnotator(\n",
    "    color=sv.Color.from_hex('#FF1493'),\n",
    "    radius=8)\n",
    "vertex_annotator_2 = sv.VertexAnnotator(\n",
    "    color=sv.Color.from_hex('#00BFFF'),\n",
    "    radius=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77e793fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "collecting crops: 3it [00:04,  1.56s/it]\n",
      "Embedding extraction: 2it [00:19,  9.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of players detected: 61\n"
     ]
    }
   ],
   "source": [
    "#Team Assignment based on colours\n",
    "#use of the SigLIP, UMAP, and KMeans combo\n",
    "import supervision as sv\n",
    "from tqdm import tqdm\n",
    "from utils.teamclassifier import TeamClassifier\n",
    "\n",
    "PLAYER_ID = 2\n",
    "STRIDE = 60\n",
    "frame_generator = sv.get_video_frames_generator(\n",
    "    source_path=SOURCE_VIDEO_PATH, stride=STRIDE\n",
    ")\n",
    "\n",
    "crops = []\n",
    "for frame in tqdm(frame_generator, desc=\"collecting crops\"):\n",
    "    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "    detections = sv.Detections.from_inference(result)\n",
    "    players_detections = detections[detections.class_id == PLAYER_ID]\n",
    "    \n",
    "    # Skip the frame if no players are detected\n",
    "    if len(players_detections.xyxy) == 0:\n",
    "        continue\n",
    "    \n",
    "    players_crops = [sv.crop_image(frame, xyxy) for xyxy in players_detections.xyxy]\n",
    "    crops += players_crops\n",
    "\n",
    "# Ensure there are enough crops for clustering\n",
    "if len(crops) < 2:\n",
    "    print(\"Not enough player crops detected. Skipping team classification.\")\n",
    "else:\n",
    "    team_classifier = TeamClassifier(device=\"cpu\")\n",
    "    team_classifier.fit(crops)\n",
    "    \n",
    "print(f\"Number of players detected: {len(crops)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96389a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GK Assignment - calculate avg centroid of players and assign GK to the team with the closest centroid\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "\n",
    "def resolve_goalkeepers_team_id(\n",
    "    players: sv.Detections,\n",
    "    goalkeepers: sv.Detections\n",
    ") -> np.ndarray:\n",
    "    goalkeepers_xy = goalkeepers.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "    players_xy = players.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "    team_0_centroid = players_xy[players.class_id == 0].mean(axis=0)\n",
    "    team_1_centroid = players_xy[players.class_id == 1].mean(axis=0)\n",
    "    goalkeepers_team_id = []\n",
    "    for goalkeeper_xy in goalkeepers_xy:\n",
    "        dist_0 = np.linalg.norm(goalkeeper_xy - team_0_centroid)\n",
    "        dist_1 = np.linalg.norm(goalkeeper_xy - team_1_centroid)\n",
    "        goalkeepers_team_id.append(0 if dist_0 < dist_1 else 1)\n",
    "\n",
    "    return np.array(goalkeepers_team_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60775edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 152it [00:01, 101.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames collected: 31\n"
     ]
    }
   ],
   "source": [
    "#Frame collection for training\n",
    "from tqdm import tqdm\n",
    "\n",
    "frames = []\n",
    "\n",
    "for frame_index, frame in enumerate(tqdm(sv.get_video_frames_generator(SOURCE_VIDEO_PATH), desc=\"Processing...\")):\n",
    "    if frame_index % 5 == 0: #default: 5\n",
    "        frames.append(frame)\n",
    "\n",
    "print(f\"Total frames collected: {len(frames)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b77e50ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:   0%|          | 0/31 [00:00<?, ?it/s]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:05,  5.44s/it]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:   3%|▎         | 1/31 [00:08<04:21,  8.71s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:06,  6.01s/it]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:   6%|▋         | 2/31 [00:17<04:18,  8.93s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:05,  5.27s/it]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  10%|▉         | 3/31 [00:25<04:00,  8.58s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:04,  4.99s/it]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  13%|█▎        | 4/31 [00:33<03:41,  8.20s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:05,  5.11s/it]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  16%|█▌        | 5/31 [00:41<03:28,  8.01s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:04,  4.82s/it]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  19%|█▉        | 6/31 [00:48<03:15,  7.82s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:05,  5.14s/it]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  23%|██▎       | 7/31 [00:56<03:07,  7.81s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:05,  5.23s/it]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  26%|██▌       | 8/31 [01:04<02:57,  7.74s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:05,  5.60s/it]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  29%|██▉       | 9/31 [01:12<02:55,  7.97s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:04,  4.83s/it]\n",
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 10: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  32%|███▏      | 10/31 [01:19<02:42,  7.72s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:04,  4.59s/it]\n",
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 11: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  35%|███▌      | 11/31 [01:27<02:32,  7.63s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:05,  5.65s/it]\n",
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 12: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  39%|███▊      | 12/31 [01:35<02:31,  7.98s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:05,  5.43s/it]\n",
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 13: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  42%|████▏     | 13/31 [01:44<02:25,  8.08s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:05,  5.49s/it]\n",
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 14: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  45%|████▌     | 14/31 [01:52<02:18,  8.15s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:05,  5.06s/it]\n",
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 15: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  48%|████▊     | 15/31 [02:00<02:08,  8.05s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:04,  4.39s/it]\n",
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 16: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  52%|█████▏    | 16/31 [02:07<01:54,  7.67s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:04,  4.83s/it]\n",
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 17: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  55%|█████▍    | 17/31 [02:14<01:45,  7.52s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:04,  4.81s/it]\n",
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 18: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  58%|█████▊    | 18/31 [02:21<01:37,  7.49s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:04,  4.77s/it]\n",
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 19: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  61%|██████▏   | 19/31 [02:29<01:29,  7.44s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:04,  4.46s/it]\n",
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 20: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  65%|██████▍   | 20/31 [02:36<01:20,  7.29s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:04,  4.45s/it]\n",
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 21: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  68%|██████▊   | 21/31 [02:43<01:12,  7.28s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:04,  4.30s/it]\n",
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 22: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  71%|███████   | 22/31 [02:50<01:04,  7.15s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:04,  4.16s/it]\n",
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 23: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  74%|███████▍  | 23/31 [02:56<00:56,  7.03s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:03,  3.94s/it]\n",
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 24: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  77%|███████▋  | 24/31 [03:03<00:47,  6.85s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:04,  4.22s/it]\n",
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 25: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  81%|████████  | 25/31 [03:09<00:40,  6.80s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:04,  4.18s/it]\n",
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 26: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  84%|████████▍ | 26/31 [03:16<00:33,  6.77s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:04,  4.73s/it]\n",
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 27: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  87%|████████▋ | 27/31 [03:23<00:27,  6.89s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:04,  4.54s/it]\n",
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 28: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  90%|█████████ | 28/31 [03:31<00:20,  7.00s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:04,  4.66s/it]\n",
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 29: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  94%|█████████▎| 29/31 [03:38<00:14,  7.04s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:05,  5.47s/it]\n",
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... frame 30: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:  97%|█████████▋| 30/31 [03:46<00:07,  7.47s/it]\n",
      "Embedding extraction: 0it [00:00, ?it/s]\n",
      "Embedding extraction: 1it [00:04,  4.96s/it]\n",
      "Processing...: 100%|██████████| 31/31 [03:54<00:00,  7.57s/it]\n"
     ]
    }
   ],
   "source": [
    "#Full tracking\n",
    "import supervision as sv\n",
    "from utils.viewtransformer import ViewTransformer\n",
    "from utils.drawpitch import draw_pitch, draw_points_on_pitch\n",
    "\n",
    "pitch_frames = []\n",
    "\n",
    "ball_coords = []\n",
    "gk_t1_coords = []\n",
    "gk_t2_coords = []\n",
    "\n",
    "player_coords_per_id = dict()\n",
    "player_team_per_id = {}\n",
    "\n",
    "# Tracker\n",
    "tracker = sv.ByteTrack()\n",
    "\n",
    "for frame_index, frame in enumerate(tqdm(frames, desc=\"Processing...\")):\n",
    "    tqdm.write(f\"... frame {frame_index}: \")\n",
    "    \n",
    "    # ball and players detections\n",
    "    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.2)[0]\n",
    "    detections = sv.Detections.from_inference(result)\n",
    "\n",
    "    ball_detections = detections[detections.class_id == BALL_ID]\n",
    "    ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
    "    \n",
    "    all_detections = detections[detections.class_id != BALL_ID]\n",
    "    all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)\n",
    "    all_detections = tracker.update_with_detections(detections=all_detections)\n",
    "\n",
    "    goalkeepers_detections = all_detections[all_detections.class_id == GOALKEEPER_ID]\n",
    "    players_detections = all_detections[all_detections.class_id == PLAYER_ID]\n",
    "\n",
    "    # team assignment\n",
    "    players_crops = [sv.crop_image(frame, xyxy) for xyxy in players_detections.xyxy]\n",
    "    players_detections.class_id = team_classifier.predict(players_crops)\n",
    "\n",
    "    if len(goalkeepers_detections.xyxy) > 0:\n",
    "        goalkeepers_detections.class_id = resolve_goalkeepers_team_id(\n",
    "            players_detections, goalkeepers_detections)\n",
    "    else:\n",
    "        #if no gk detected no need to resolve team id\n",
    "        goalkeepers_detections.class_id = np.array([])\n",
    "    \n",
    "    all_detections = sv.Detections.merge([players_detections, goalkeepers_detections])\n",
    "\n",
    "    # frame visualization\n",
    "    labels = []\n",
    "    for idx, tracker_id in enumerate(all_detections.tracker_id):\n",
    "        class_id = all_detections.class_id[idx]\n",
    "        if tracker_id in player_team_per_id:\n",
    "            team = player_team_per_id[tracker_id]\n",
    "        else:\n",
    "            team = class_id\n",
    "        labels.append(f\"id_{tracker_id}_t_{team}\")\n",
    "\n",
    "    all_detections.class_id = all_detections.class_id.astype(int)\n",
    "\n",
    "    annotated_frame = frame.copy()\n",
    "    annotated_frame = ellipse_annotator.annotate(\n",
    "        scene=annotated_frame,\n",
    "        detections=all_detections)\n",
    "    annotated_frame = label_annotator.annotate(\n",
    "        scene=annotated_frame,\n",
    "        detections=all_detections,\n",
    "        labels=labels)\n",
    "    annotated_frame = triangle_annotator.annotate(\n",
    "        scene=annotated_frame,\n",
    "        detections=ball_detections)\n",
    "\n",
    "    pitch_frames.append(annotated_frame.copy())\n",
    "    \n",
    "    players_detections = sv.Detections.merge([\n",
    "        players_detections, goalkeepers_detections\n",
    "    ])\n",
    "    \n",
    "    # Detect pitch key points\n",
    "    result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "    key_points = sv.KeyPoints.from_inference(result)\n",
    "    \n",
    "    # Ensure key_points is not None and contains valid data\n",
    "    if key_points is None or key_points.confidence is None:\n",
    "        print(f\"Skipping frame {frame_index} due to missing key points.\")\n",
    "        continue  # Skip this frame and move to the next one\n",
    "\n",
    "    # project ball, players and gk on pitch\n",
    "    filter = key_points.confidence[0] > 0.5\n",
    "    frame_reference_points = key_points.xy[0][filter]\n",
    "    pitch_reference_points = np.array(CONFIG.vertices)[filter]\n",
    "\n",
    "    # Ensure there are at least 4 points for homography calculation\n",
    "    if len(frame_reference_points) < 4 or len(pitch_reference_points) < 4:\n",
    "        print(f\"Skipping frame due to insufficient keypoints: {len(frame_reference_points)} found.\")\n",
    "        continue  # Skip this frame and move to the next one\n",
    "\n",
    "    # Proceed with homography calculation\n",
    "    transformer = ViewTransformer(\n",
    "        source = frame_reference_points,\n",
    "        target = pitch_reference_points\n",
    "    )\n",
    "\n",
    "    frame_ball_xy = ball_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "    pitch_ball_xy = transformer.transform_points(points=frame_ball_xy)\n",
    "\n",
    "    players_xy = players_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "    pitch_players_xy = transformer.transform_points(points=players_xy)\n",
    "    \n",
    "    # --- Save player coordinates per ID in pitch space ---\n",
    "    for idx, tracker_id in enumerate(players_detections.tracker_id):\n",
    "        if tracker_id is not None:\n",
    "            if tracker_id not in player_coords_per_id:\n",
    "                player_coords_per_id[tracker_id] = []\n",
    "                # Save the team assignment for this tracker_id\n",
    "                player_team_per_id[tracker_id] = int(players_detections.class_id[idx])\n",
    "            x, y = pitch_players_xy[idx]\n",
    "            player_coords_per_id[tracker_id].append((frame_index, x, y))\n",
    "\n",
    "    # --- Save ball coordinates in pitch space ---\n",
    "    if len(pitch_ball_xy) > 0:\n",
    "        x, y = pitch_ball_xy[0]\n",
    "        ball_coords.append((frame_index, x, y))\n",
    "    else:\n",
    "        ball_coords.append((frame_index, None, None))\n",
    "\n",
    "    # --- Save goalkeeper coordinates for each team in pitch space ---\n",
    "    # Find goalkeepers in players_detections (merged with goalkeepers)\n",
    "    gk_indices = np.where(players_detections.class_id == GOALKEEPER_ID)[0]\n",
    "    for idx in gk_indices:\n",
    "        x, y = pitch_players_xy[idx]\n",
    "        # Use the original team assignment for GKs\n",
    "        team_id = resolve_goalkeepers_team_id(players_detections, players_detections[idx:idx+1])[0]\n",
    "        if team_id == 0:\n",
    "            gk_t1_coords.append((frame_index, x, y))\n",
    "        elif team_id == 1:\n",
    "            gk_t2_coords.append((frame_index, x, y)) \n",
    "    \n",
    "    if frame_index > 30: #bytetrack memory is 30 frames\n",
    "        tracker.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1de79c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save frames with detections to folder\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "video_name = os.path.splitext(os.path.basename(SOURCE_VIDEO_PATH))[0]\n",
    "\n",
    "frames_len = len(frames)\n",
    "\n",
    "output_dir = f\"../../data/frames/{video_name}-{frames_len}f\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for idx, frame in enumerate(pitch_frames):\n",
    "    frame_path = os.path.join(output_dir, f\"frame_{idx:04d}.png\")\n",
    "    \n",
    "    cv2.imwrite(frame_path,np.array(frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25b4ef8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates per frame saved to ../../data/coords/new5s-31f.csv\n"
     ]
    }
   ],
   "source": [
    "#Save coordinates per frame to CSV\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "video_name = os.path.splitext(os.path.basename(SOURCE_VIDEO_PATH))[0]\n",
    "\n",
    "output_csv_path = f\"../../data/coords/{video_name}-{frames_len}f.csv\" \n",
    "all_ids = sorted(player_coords_per_id.keys())\n",
    "\n",
    "# Build lookups\n",
    "frame_lookup = {}\n",
    "for tracker_id, coords in player_coords_per_id.items():\n",
    "    for frame_index, x, y in coords:\n",
    "        if frame_index not in frame_lookup:\n",
    "            frame_lookup[frame_index] = {}\n",
    "        frame_lookup[frame_index][tracker_id] = [x, y]\n",
    "\n",
    "ball_lookup = {f: [x, y] for f, x, y in ball_coords}\n",
    "\n",
    "header = (\n",
    "    [\"frame_index\", \"ball\"] +\n",
    "    [f\"id_{id}_team_{player_team_per_id[id]}\" for id in all_ids]\n",
    ")\n",
    "\n",
    "all_frames = sorted(set(\n",
    "    list(frame_lookup.keys()) +\n",
    "    list(ball_lookup.keys())\n",
    "))\n",
    "\n",
    "with open(output_csv_path, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    for frame_index in all_frames:\n",
    "        row = [frame_index]\n",
    "        # Ball\n",
    "        ball = ball_lookup.get(frame_index, None)\n",
    "        if ball and None not in ball:\n",
    "            row.append(f\"{ball[0]:.2f},{ball[1]:.2f}\")\n",
    "        else:\n",
    "            row.append(\"\")\n",
    "        # Players by id\n",
    "        for id in all_ids:\n",
    "            coord = frame_lookup.get(frame_index, {}).get(id, None)\n",
    "            if coord and None not in coord:\n",
    "                row.append(f\"{coord[0]:.2f},{coord[1]:.2f}\")\n",
    "            else:\n",
    "                row.append(\"\")\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"Coordinates per frame saved to {output_csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
