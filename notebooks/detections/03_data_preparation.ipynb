{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e3fb4be",
   "metadata": {},
   "source": [
    "03. DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3144b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "filepath = '../../data/coords/old10s-60f.csv'\n",
    "\n",
    "df = pd.read_csv(filepath)\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f00f60d",
   "metadata": {},
   "source": [
    "Create good subsets of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001d429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the frame index column (assume it's the first column)\n",
    "data_cols = df.columns[1:]\n",
    "\n",
    "# Count non-empty (non-NaN) cells per row\n",
    "df['detection_count'] = df[data_cols].notnull().sum(axis=1)\n",
    "\n",
    "# Find indices of good frames\n",
    "good_mask = df['detection_count'] > 18\n",
    "\n",
    "# Find all consecutive subsets of good frames (no min length)\n",
    "subsets = []\n",
    "start = None\n",
    "for idx, is_good in enumerate(good_mask):\n",
    "    if is_good:\n",
    "        if start is None:\n",
    "            start = idx\n",
    "    else:\n",
    "        if start is not None:\n",
    "            subsets.append((start, idx))\n",
    "            start = None\n",
    "# Handle sequence that goes to the end\n",
    "if start is not None:\n",
    "    subsets.append((start, len(df)))\n",
    "\n",
    "# Save each subset as a CSV\n",
    "import os\n",
    "os.makedirs('../../data/data_preparation/subsets', exist_ok=True)\n",
    "for i, (start, end) in enumerate(subsets):\n",
    "    if end - start >= 10:\n",
    "        subset = df.iloc[start:end]\n",
    "        subset.to_csv(f'../../data/data_preparation/subsets/subset{i+1}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aa8dc7",
   "metadata": {},
   "source": [
    "See Transitions of ids or detect ids of referees or other entities - manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6566ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop empty columns\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "#drop extra columns\n",
    "df = df.drop(columns=['detection_count'])\n",
    "\n",
    "#IDs to remove\n",
    "#ids: 11 - referee, 24 - referee\n",
    "df = df.drop(columns=['id_11_team_1'])\n",
    "df = df.drop(columns=['id_24_team_1'])\n",
    "df = df.drop(columns=['gk0'])\n",
    "df = df.drop(columns=['gk1'])\n",
    "df = df.rename(columns={'id_23_team_1': 'gk0'})\n",
    "\n",
    "#IDs with no Transitions\n",
    "#ids:1,3,4,5,6,9,10,12,13,14,15,19,22\n",
    "\n",
    "#IDs with Transitions\n",
    "#ids: 2,7,8,16,17,18\n",
    "\n",
    "#id2 lt f14 -> id43\n",
    "df.loc[14:, 'id_2_team_1'] = df.loc[14:, 'id_43_team_1']\n",
    "df = df.drop(columns=['id_43_team_1'])\n",
    "\n",
    "#id7 lt f3-6 -> id 29\n",
    "df.loc[7:, 'id_7_team_1'] = df.loc[7:, 'id_29_team_1']\n",
    "df = df.drop(columns=['id_29_team_1'])\n",
    "\n",
    "#id8 lt f9 -> id34\n",
    "df.loc[9:, 'id_8_team_1'] = df.loc[9:, 'id_34_team_1']\n",
    "df = df.drop(columns=['id_34_team_1'])\n",
    "\n",
    "#id16 lt f20 -> id53\n",
    "df.loc[20:, 'id_16_team_0'] = df.loc[20:, 'id_53_team_0']\n",
    "df = df.drop(columns=['id_53_team_0'])\n",
    "\n",
    "#id17 lt f5-6 -> id30 lt f8-12 -> id39\n",
    "df.loc[6:, 'id_17_team_1'] = df.loc[6:, 'id_30_team_1']\n",
    "df.loc[12:, 'id_17_team_1'] = df.loc[12:, 'id_39_team_1']\n",
    "df = df.drop(columns=['id_30_team_1', 'id_39_team_1'])\n",
    "\n",
    "#id18f1 lt f2 -> id18 lt f9-10 -> id36 lt f12-15 -> id44\n",
    "df.loc[10:, 'id_18_team_1'] = df.loc[10:, 'id_36_team_1']\n",
    "df.loc[15:, 'id_18_team_1'] = df.loc[15:, 'id_44_team_1']\n",
    "df = df.drop(columns=['id_36_team_1', 'id_44_team_1'])\n",
    "\n",
    "#id18f2 lt f3-5 -> id28\n",
    "df.loc[df['frame_index'] == 2, 'id_28_team_0'] = df.loc[df['frame_index'] == 2, 'id_18_team_1']\n",
    "df.loc[df['frame_index'] == 2, 'id_18_team_1'] = np.nan\n",
    "\n",
    "#save cleaned subset\n",
    "#df.to_csv(subset, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa55eacd",
   "metadata": {},
   "source": [
    "Interpolate good subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a219c838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not working\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../data/train/ss1.csv')\n",
    "\n",
    "# Convert all columns except the index (if any) to numeric, coercing errors to NaN\n",
    "for col in df.columns:\n",
    "    if col != 'frame':  # replace 'frame' with your index column if needed\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Interpolate all numeric columns (coordinates)\n",
    "df.interpolate(method='linear', limit_direction='both', inplace=True)\n",
    "\n",
    "# Save the interpolated DataFrame\n",
    "df.to_csv('../../data/train/ss1_interpolated.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
